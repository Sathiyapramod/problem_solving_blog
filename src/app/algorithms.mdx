# Algorithms ⚡

Algorithms are step-by-step procedures for solving problems. Understanding algorithms is essential for writing efficient code.

## Table of Contents

- [Sorting Algorithms](#sorting-algorithms)
- [Searching Algorithms](#searching-algorithms)
- [Dynamic Programming](#dynamic-programming)
- [Greedy Algorithms](#greedy-algorithms)
- [Graph Algorithms](#graph-algorithms)
- [String Algorithms](#string-algorithms)

## Sorting Algorithms

### Bubble Sort

Simple but inefficient sorting algorithm.

```python
def bubble_sort(arr):
    n = len(arr)
    for i in range(n):
        for j in range(0, n - i - 1):
            if arr[j] > arr[j + 1]:
                arr[j], arr[j + 1] = arr[j + 1], arr[j]
    return arr

# Time Complexity: O(n²)
# Space Complexity: O(1)
```

### Selection Sort

Finds the minimum element and places it at the beginning.

```python
def selection_sort(arr):
    n = len(arr)
    for i in range(n):
        min_idx = i
        for j in range(i + 1, n):
            if arr[j] < arr[min_idx]:
                min_idx = j
        arr[i], arr[min_idx] = arr[min_idx], arr[i]
    return arr

# Time Complexity: O(n²)
# Space Complexity: O(1)
```

### Insertion Sort

Builds the final array one item at a time.

```python
def insertion_sort(arr):
    for i in range(1, len(arr)):
        key = arr[i]
        j = i - 1
        while j >= 0 and arr[j] > key:
            arr[j + 1] = arr[j]
            j -= 1
        arr[j + 1] = key
    return arr

# Time Complexity: O(n²) worst case, O(n) best case
# Space Complexity: O(1)
```

### Merge Sort

Divide and conquer algorithm with stable sorting.

```python
def merge_sort(arr):
    if len(arr) <= 1:
        return arr

    mid = len(arr) // 2
    left = merge_sort(arr[:mid])
    right = merge_sort(arr[mid:])

    return merge(left, right)

def merge(left, right):
    result = []
    i = j = 0

    while i < len(left) and j < len(right):
        if left[i] <= right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1

    result.extend(left[i:])
    result.extend(right[j:])
    return result

# Time Complexity: O(n log n)
# Space Complexity: O(n)
```

### Quick Sort

Efficient, in-place sorting algorithm.

```python
def quick_sort(arr):
    if len(arr) <= 1:
        return arr

    pivot = arr[len(arr) // 2]
    left = [x for x in arr if x < pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]

    return quick_sort(left) + middle + quick_sort(right)

# Time Complexity: O(n log n) average, O(n²) worst case
# Space Complexity: O(log n)
```

## Searching Algorithms

### Linear Search

Simple search through each element sequentially.

```python
def linear_search(arr, target):
    for i, element in enumerate(arr):
        if element == target:
            return i
    return -1

# Time Complexity: O(n)
# Space Complexity: O(1)
```

### Binary Search

Efficient search on sorted arrays.

```python
def binary_search(arr, target):
    left, right = 0, len(arr) - 1

    while left <= right:
        mid = (left + right) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1

    return -1

# Time Complexity: O(log n)
# Space Complexity: O(1)
```

### Binary Search (Recursive)

```python
def binary_search_recursive(arr, target, left=0, right=None):
    if right is None:
        right = len(arr) - 1

    if left > right:
        return -1

    mid = (left + right) // 2

    if arr[mid] == target:
        return mid
    elif arr[mid] < target:
        return binary_search_recursive(arr, target, mid + 1, right)
    else:
        return binary_search_recursive(arr, target, left, mid - 1)
```

## Dynamic Programming

Dynamic programming solves complex problems by breaking them into simpler subproblems.

### Fibonacci Sequence

```python
def fibonacci_recursive(n):
    if n <= 1:
        return n
    return fibonacci_recursive(n - 1) + fibonacci_recursive(n - 2)

def fibonacci_dp(n):
    if n <= 1:
        return n

    dp = [0] * (n + 1)
    dp[1] = 1

    for i in range(2, n + 1):
        dp[i] = dp[i - 1] + dp[i - 2]

    return dp[n]

# Time Complexity: O(n) for DP, O(2^n) for recursive
# Space Complexity: O(n) for DP, O(n) for recursive
```

### Longest Common Subsequence (LCS)

```python
def lcs(str1, str2):
    m, n = len(str1), len(str2)
    dp = [[0] * (n + 1) for _ in range(m + 1)]

    for i in range(1, m + 1):
        for j in range(1, n + 1):
            if str1[i - 1] == str2[j - 1]:
                dp[i][j] = dp[i - 1][j - 1] + 1
            else:
                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])

    return dp[m][n]

# Time Complexity: O(m * n)
# Space Complexity: O(m * n)
```

### Coin Change Problem

```python
def coin_change(coins, amount):
    dp = [float('inf')] * (amount + 1)
    dp[0] = 0

    for coin in coins:
        for i in range(coin, amount + 1):
            dp[i] = min(dp[i], dp[i - coin] + 1)

    return dp[amount] if dp[amount] != float('inf') else -1

# Time Complexity: O(amount * len(coins))
# Space Complexity: O(amount)
```

## Greedy Algorithms

Greedy algorithms make locally optimal choices at each step.

### Activity Selection Problem

```python
def activity_selection(start, finish):
    n = len(start)
    selected = [0]  # First activity is always selected
    j = 0

    for i in range(1, n):
        if start[i] >= finish[j]:
            selected.append(i)
            j = i

    return selected

# Time Complexity: O(n log n) if not sorted
# Space Complexity: O(1)
```

### Fractional Knapsack

```python
def fractional_knapsack(weights, values, capacity):
    n = len(weights)
    items = [(values[i] / weights[i], weights[i], values[i]) for i in range(n)]
    items.sort(reverse=True)  # Sort by value per weight

    total_value = 0
    remaining_capacity = capacity

    for value_per_weight, weight, value in items:
        if remaining_capacity >= weight:
            total_value += value
            remaining_capacity -= weight
        else:
            total_value += value_per_weight * remaining_capacity
            break

    return total_value

# Time Complexity: O(n log n)
# Space Complexity: O(n)
```

## Graph Algorithms

### Dijkstra's Shortest Path

```python
import heapq

def dijkstra(graph, start):
    distances = {node: float('inf') for node in graph}
    distances[start] = 0
    pq = [(0, start)]

    while pq:
        current_distance, current_node = heapq.heappop(pq)

        if current_distance > distances[current_node]:
            continue

        for neighbor, weight in graph[current_node].items():
            distance = current_distance + weight

            if distance < distances[neighbor]:
                distances[neighbor] = distance
                heapq.heappush(pq, (distance, neighbor))

    return distances

# Time Complexity: O((V + E) log V)
# Space Complexity: O(V)
```

### Depth-First Search (DFS)

```python
def dfs(graph, start, visited=None):
    if visited is None:
        visited = set()

    visited.add(start)
    print(start, end=" ")

    for neighbor in graph[start]:
        if neighbor not in visited:
            dfs(graph, neighbor, visited)

# Time Complexity: O(V + E)
# Space Complexity: O(V)
```

### Breadth-First Search (BFS)

```python
from collections import deque

def bfs(graph, start):
    visited = set()
    queue = deque([start])
    visited.add(start)

    while queue:
        vertex = queue.popleft()
        print(vertex, end=" ")

        for neighbor in graph[vertex]:
            if neighbor not in visited:
                visited.add(neighbor)
                queue.append(neighbor)

# Time Complexity: O(V + E)
# Space Complexity: O(V)
```

## String Algorithms

### KMP Pattern Matching

```python
def kmp_search(text, pattern):
    def compute_lps(pattern):
        lps = [0] * len(pattern)
        length = 0
        i = 1

        while i < len(pattern):
            if pattern[i] == pattern[length]:
                length += 1
                lps[i] = length
                i += 1
            else:
                if length != 0:
                    length = lps[length - 1]
                else:
                    lps[i] = 0
                    i += 1

        return lps

    lps = compute_lps(pattern)
    i = j = 0

    while i < len(text):
        if pattern[j] == text[i]:
            i += 1
            j += 1

        if j == len(pattern):
            return i - j
        elif i < len(text) and pattern[j] != text[i]:
            if j != 0:
                j = lps[j - 1]
            else:
                i += 1

    return -1

# Time Complexity: O(n + m)
# Space Complexity: O(m)
```

### Longest Palindromic Substring

```python
def longest_palindrome(s):
    def expand_around_center(left, right):
        while left >= 0 and right < len(s) and s[left] == s[right]:
            left -= 1
            right += 1
        return s[left + 1:right]

    if len(s) < 2:
        return s

    longest = ""
    for i in range(len(s)):
        # Odd length palindromes
        palindrome1 = expand_around_center(i, i)
        # Even length palindromes
        palindrome2 = expand_around_center(i, i + 1)

        if len(palindrome1) > len(longest):
            longest = palindrome1
        if len(palindrome2) > len(longest):
            longest = palindrome2

    return longest

# Time Complexity: O(n²)
# Space Complexity: O(1)
```

## Algorithm Complexity Analysis

### Big O Notation

- **O(1)**: Constant time
- **O(log n)**: Logarithmic time
- **O(n)**: Linear time
- **O(n log n)**: Linearithmic time
- **O(n²)**: Quadratic time
- **O(2ⁿ)**: Exponential time

### Common Time Complexities

| Algorithm      | Best Case  | Average Case | Worst Case |
| -------------- | ---------- | ------------ | ---------- |
| Bubble Sort    | O(n)       | O(n²)        | O(n²)      |
| Selection Sort | O(n²)      | O(n²)        | O(n²)      |
| Insertion Sort | O(n)       | O(n²)        | O(n²)      |
| Merge Sort     | O(n log n) | O(n log n)   | O(n log n) |
| Quick Sort     | O(n log n) | O(n log n)   | O(n²)      |
| Linear Search  | O(1)       | O(n)         | O(n)       |
| Binary Search  | O(1)       | O(log n)     | O(log n)   |

## Practice Problems

### Problem 1: Two Sum

```python
def two_sum(nums, target):
    seen = {}
    for i, num in enumerate(nums):
        complement = target - num
        if complement in seen:
            return [seen[complement], i]
        seen[num] = i
    return []

# Time Complexity: O(n)
# Space Complexity: O(n)
```

### Problem 2: Valid Parentheses

```python
def is_valid_parentheses(s):
    stack = []
    brackets = {')': '(', '}': '{', ']': '['}

    for char in s:
        if char in '({[':
            stack.append(char)
        elif char in ')}]':
            if not stack or stack.pop() != brackets[char]:
                return False

    return len(stack) == 0

# Time Complexity: O(n)
# Space Complexity: O(n)
```

## Next Steps

Now that you understand algorithms, you're ready to:

1. Practice [Problem Solving](/problem-solving)
2. Prepare for [Interview Questions](/interview-prep)
3. Build [Projects](/projects)

---

**Remember**: Practice is key to mastering algorithms. Implement them from scratch and solve problems regularly!
